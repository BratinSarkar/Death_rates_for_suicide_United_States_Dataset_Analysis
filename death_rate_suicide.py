# -*- coding: utf-8 -*-
"""death_rate_suicide.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1k2CV1Mv37kBIYdGmIEqzwnAivZQKanCl
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Load the dataset
data = pd.read_csv('Death_rates_for_suicide_United_States.csv')

# Inspect the data
print(data.head())
print(data.info())
print(data.describe())
print("\nUnique values in columns:")
print(data.nunique())

# Check for missing values
print("\nMissing values in each column:")
print(data.isnull().sum())

# Convert YEAR and AGE_NUM to integers for analysis
data['YEAR'] = data['YEAR'].astype(int)
data['AGE_NUM'] = data['AGE_NUM'].astype(int)

# Check if 'Estimate' column exists before filling NaNs
if 'Estimate' in data.columns:
    # Fill numerical columns with zeros
    data['Estimate'].fillna(0, inplace=True)
else:
    # Print a warning or handle the case where 'Estimate' column is missing
    print("Warning: 'Estimate' column not found in the DataFrame.")

# Fill missing values (if any) with 0 or an appropriate strategy
data.fillna(0, inplace=True)

# Filter data for analysis of all persons and all ages
all_persons_all_ages = data[(data['STUB_NAME'] == 'Total') & (data['AGE'] == 'All ages')]

# Line plot for trends over time
plt.figure(figsize=(10, 6))
sns.lineplot(data=all_persons_all_ages, x='YEAR', y='ESTIMATE', marker='o')
plt.title('Trend of Suicide Rates Over Time (1950-2020)')
plt.xlabel('Year')
plt.ylabel('Death Rates (per 100,000)')
plt.grid()
plt.show()

# Analyze suicide rates by age group
age_group_data = data[data['STUB_NAME'] == 'Total']

plt.figure(figsize=(12, 8))
sns.lineplot(data=age_group_data, x='YEAR', y='ESTIMATE', hue='AGE', marker='o')
plt.title('Suicide Rates Over Time by Age Group')
plt.xlabel('Year')
plt.ylabel('Death Rates (per 100,000)')
plt.legend(title='Age Group')
plt.grid()
plt.show()

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score

# Prepare data for regression
X = all_persons_all_ages[['YEAR']]
y = all_persons_all_ages['ESTIMATE']

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train a Linear Regression model
model = LinearRegression()
model.fit(X_train, y_train)

# Predictions
y_pred = model.predict(X_test)

# Evaluate the model
print("\nRegression Results:")
print("Mean Squared Error:", mean_squared_error(y_test, y_pred))
print("R-squared:", r2_score(y_test, y_pred))

# Forecast future rates
future_years = pd.DataFrame({'YEAR': range(2021, 2031)})
future_rates = model.predict(future_years)

# Plot forecast
plt.figure(figsize=(10, 6))
plt.plot(all_persons_all_ages['YEAR'], all_persons_all_ages['ESTIMATE'], label='Historical Data', marker='o')
plt.plot(future_years['YEAR'], future_rates, label='Forecast', linestyle='--', color='red')
plt.title('Suicide Rates Forecast (2021-2030)')
plt.xlabel('Year')
plt.ylabel('Death Rates (per 100,000)')
plt.legend()
plt.grid()
plt.show()

from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler

# Standardize the data for clustering
scaler = StandardScaler()
scaled_data = scaler.fit_transform(data[['YEAR_NUM', 'ESTIMATE']])

# Apply K-Means clustering
kmeans = KMeans(n_clusters=3, random_state=42)
data['Cluster'] = kmeans.fit_predict(scaled_data)

# Visualize clusters
plt.figure(figsize=(10, 6))
sns.scatterplot(data=data, x='YEAR', y='ESTIMATE', hue='Cluster', palette='viridis')
plt.title('Clustering of Suicide Rates Over Time')
plt.xlabel('Year')
plt.ylabel('Death Rates (per 100,000)')
plt.legend(title='Cluster')
plt.grid()
plt.show()

# Calculate percentage change
all_persons_all_ages['Yearly_Change'] = all_persons_all_ages['ESTIMATE'].pct_change() * 100

# Plot percentage change over time
plt.figure(figsize=(10, 6))
sns.barplot(data=all_persons_all_ages, x='YEAR', y='Yearly_Change', palette='coolwarm')
plt.title('Year-on-Year Percentage Change in Suicide Rates')
plt.xlabel('Year')
plt.ylabel('Percentage Change (%)')
plt.axhline(0, color='black', linestyle='--')
plt.grid()
plt.show()

# Correlation matrix
# Exclude non-numeric columns before calculating correlations
correlation_matrix = data.select_dtypes(include=['number']).corr()

# Plot heatmap of correlations
plt.figure(figsize=(12, 8))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f")
plt.title('Correlation Matrix of Dataset Features')
plt.show()

# Calculate changes for each age group
age_group_changes = data.groupby('AGE')['ESTIMATE'].diff()

# Add change column
data['Rate_Change'] = age_group_changes

# Filter significant changes (e.g., changes greater than 5)
significant_changes = data[abs(data['Rate_Change']) > 5]

print("Significant Changes in Age Groups:")
print(significant_changes[['YEAR', 'AGE', 'ESTIMATE', 'Rate_Change']])

from statsmodels.tsa.arima.model import ARIMA
from sklearn.metrics import mean_squared_error

# Prepare data for ARIMA
time_series = all_persons_all_ages.set_index('YEAR')['ESTIMATE']

# Fit ARIMA model
model = ARIMA(time_series, order=(1, 1, 1))
model_fit = model.fit()

# Forecast future values
forecast = model_fit.forecast(steps=10)

# Plot the forecast
plt.figure(figsize=(10, 6))
plt.plot(time_series, label='Historical Data')
plt.plot(range(2021, 2031), forecast, label='Forecast', linestyle='--', color='red')
plt.title('ARIMA Forecast of Suicide Rates')
plt.xlabel('Year')
plt.ylabel('Death Rates (per 100,000)')
plt.legend()
plt.grid()
plt.show()

# Model summary
print(model_fit.summary())

from sklearn.ensemble import RandomForestRegressor
from sklearn.feature_selection import SelectFromModel

# Prepare feature set and target
features = data[['YEAR_NUM', 'AGE_NUM', 'STUB_NAME_NUM', 'STUB_LABEL_NUM']]
target = data['ESTIMATE']

# Train Random Forest Regressor
rf_model = RandomForestRegressor(random_state=42)
rf_model.fit(features, target)

# Feature importance
importances = rf_model.feature_importances_
feature_names = features.columns
importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances})
importance_df.sort_values(by='Importance', ascending=False, inplace=True)

print("Feature Importance:")
print(importance_df)

# Plot feature importance
plt.figure(figsize=(8, 6))
sns.barplot(data=importance_df, x='Importance', y='Feature', palette='viridis')
plt.title('Feature Importance from Random Forest')
plt.show()

from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler

# Data for clustering
clustering_data = data[['YEAR_NUM', 'AGE_NUM', 'ESTIMATE']]

# Standardize the data
scaler = StandardScaler()
scaled_clustering_data = scaler.fit_transform(clustering_data)

# Apply K-Means
kmeans = KMeans(n_clusters=3, random_state=42)
data['Cluster'] = kmeans.fit_predict(scaled_clustering_data)

# Visualize clusters
plt.figure(figsize=(10, 6))
sns.scatterplot(data=data, x='YEAR', y='ESTIMATE', hue='Cluster', palette='viridis')
plt.title('Clusters of Suicide Rates')
plt.xlabel('Year')
plt.ylabel('Death Rates (per 100,000)')
plt.legend(title='Cluster')
plt.grid()
plt.show()

